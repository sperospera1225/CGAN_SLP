2022-09-14 20:03:17,993 Progressive Transformers for End-to-End SLP
2022-09-14 20:03:18,001 Total params: 15427584
2022-09-14 20:03:18,002 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.bias', 'trg_embed.weight']
2022-09-14 20:03:18,006 cfg.data.src                       : gloss
2022-09-14 20:03:18,006 cfg.data.trg                       : skels
2022-09-14 20:03:18,006 cfg.data.files                     : files
2022-09-14 20:03:18,006 cfg.data.train                     : ./Data/tmp/train
2022-09-14 20:03:18,006 cfg.data.dev                       : ./Data/tmp/dev
2022-09-14 20:03:18,006 cfg.data.test                      : ./Data/tmp/test
2022-09-14 20:03:18,006 cfg.data.max_sent_length           : 300
2022-09-14 20:03:18,006 cfg.data.skip_frames               : 1
2022-09-14 20:03:18,006 cfg.data.src_vocab                 : ./Configs/src_vocab.txt
2022-09-14 20:03:18,006 cfg.training.random_seed           : 27
2022-09-14 20:03:18,006 cfg.training.optimizer             : adam
2022-09-14 20:03:18,007 cfg.training.learning_rate         : 0.001
2022-09-14 20:03:18,007 cfg.training.learning_rate_min     : 0.0002
2022-09-14 20:03:18,007 cfg.training.weight_decay          : 0.0
2022-09-14 20:03:18,007 cfg.training.clip_grad_norm        : 5.0
2022-09-14 20:03:18,007 cfg.training.batch_size            : 8
2022-09-14 20:03:18,007 cfg.training.scheduling            : plateau
2022-09-14 20:03:18,007 cfg.training.patience              : 7
2022-09-14 20:03:18,007 cfg.training.decrease_factor       : 0.7
2022-09-14 20:03:18,007 cfg.training.early_stopping_metric : dtw
2022-09-14 20:03:18,007 cfg.training.epochs                : 20000
2022-09-14 20:03:18,007 cfg.training.validation_freq       : 10
2022-09-14 20:03:18,007 cfg.training.logging_freq          : 250
2022-09-14 20:03:18,007 cfg.training.eval_metric           : dtw
2022-09-14 20:03:18,007 cfg.training.model_dir             : ./Models/Base
2022-09-14 20:03:18,007 cfg.training.overwrite             : True
2022-09-14 20:03:18,007 cfg.training.continue              : False
2022-09-14 20:03:18,007 cfg.training.shuffle               : True
2022-09-14 20:03:18,007 cfg.training.use_cuda              : False
2022-09-14 20:03:18,008 cfg.training.max_output_length     : 300
2022-09-14 20:03:18,008 cfg.training.keep_last_ckpts       : 1
2022-09-14 20:03:18,008 cfg.training.loss                  : MSE
2022-09-14 20:03:18,008 cfg.model.initializer              : xavier
2022-09-14 20:03:18,008 cfg.model.bias_initializer         : zeros
2022-09-14 20:03:18,008 cfg.model.embed_initializer        : xavier
2022-09-14 20:03:18,008 cfg.model.trg_size                 : 150
2022-09-14 20:03:18,008 cfg.model.just_count_in            : False
2022-09-14 20:03:18,008 cfg.model.gaussian_noise           : True
2022-09-14 20:03:18,008 cfg.model.noise_rate               : 5
2022-09-14 20:03:18,008 cfg.model.future_prediction        : 0
2022-09-14 20:03:18,008 cfg.model.encoder.type             : transformer
2022-09-14 20:03:18,008 cfg.model.encoder.num_layers       : 2
2022-09-14 20:03:18,008 cfg.model.encoder.num_heads        : 4
2022-09-14 20:03:18,008 cfg.model.encoder.embeddings.embedding_dim : 512
2022-09-14 20:03:18,008 cfg.model.encoder.embeddings.dropout : 0.0
2022-09-14 20:03:18,008 cfg.model.encoder.hidden_size      : 512
2022-09-14 20:03:18,008 cfg.model.encoder.ff_size          : 2048
2022-09-14 20:03:18,008 cfg.model.encoder.dropout          : 0.0
2022-09-14 20:03:18,009 cfg.model.decoder.type             : transformer
2022-09-14 20:03:18,009 cfg.model.decoder.num_layers       : 2
2022-09-14 20:03:18,009 cfg.model.decoder.num_heads        : 4
2022-09-14 20:03:18,009 cfg.model.decoder.embeddings.embedding_dim : 512
2022-09-14 20:03:18,009 cfg.model.decoder.embeddings.dropout : 0.0
2022-09-14 20:03:18,009 cfg.model.decoder.hidden_size      : 512
2022-09-14 20:03:18,009 cfg.model.decoder.ff_size          : 2048
2022-09-14 20:03:18,009 cfg.model.decoder.dropout          : 0.0
2022-09-14 20:03:18,009 EPOCH 1
2022-09-14 20:03:18,040 torch.Size([5, 12, 512])
2022-09-14 20:03:18,040 torch.Size([5, 184, 151])
2022-09-14 20:03:18,043 torch.Size([5, 184, 512])
2022-09-14 20:03:18,044 torch.Size([5, 196, 512])
2022-09-14 20:03:18,121 tensor([[0.5398],
        [0.5399],
        [0.5399],
        [0.5399],
        [0.5399]], grad_fn=<SigmoidBackward0>)
2022-09-14 20:03:18,139 tensor([0.5398, 0.5399, 0.5399, 0.5399, 0.5399], grad_fn=<ViewBackward0>)
2022-09-14 20:03:18,140 tensor([1., 1., 1., 1., 1.])
2022-09-14 20:03:18,597 torch.Size([5, 184, 151])
2022-09-14 20:03:18,602 torch.Size([5, 196, 512])
2022-09-14 20:03:18,602 torch.Size([5, 196, 512])
2022-09-14 20:03:18,602 torch.Size([5, 196, 512])
